# -*- coding: utf-8 -*-
"""Sentimentalanalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sP78EAbMdvIpOkFQBpmZ-2IOp9UpIBjt
"""

!mkdir -p data

!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/investigating-sentiment-analysis/data/sentiment140-subset.csv.zip -P data

!unzip -n -d data data/sentiment140-subset.csv.zip

import pandas as pd
df = pd.read_csv("data/sentiment140-subset.csv", nrows=30000)
df.head()

df.shape

df.polarity.value_counts()

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer (max_features=1000) 
vectors = vectorizer.fit_transform(df.text) 
words_df = pd. DataFrame (vectors.toarray(), columns=vectorizer.get_feature_names()) 
words_df.head()

x = words_df
y = df.polarity

from sklearn.linear_model import LogisticRegression 
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB

# Commented out IPython magic to ensure Python compatibility.
#  
# %%time
# # Create and train a logistic regression
# logreg = LogisticRegression()
# logreg.fit(x, y)

# Commented out IPython magic to ensure Python compatibility.
#  
# %%time
# # Create and train a random forest classifier
# forest = RandomForestClassifier()
# forest.fit(x, y)

# Commented out IPython magic to ensure Python compatibility.
#  
# %%time
# # Create and train a liner support vector classifier (LinearSVC)
# svc = LinearSVC()
# svc.fit(x, y)

# Commented out IPython magic to ensure Python compatibility.
#  
# %%time
# # Create and train a Multinomial naive classifier (MultinomialNB)
# bayes = LogisticRegression()
# bayes.fit(x, y)

# Create some test data
 
pd.set_option("display.max_colwidth", 200)
 
unknown = pd.DataFrame({'content': [
     "I love love love love this kitten",
     "I hate hate hate hate this keyboard",
     "I'm not sure how I feel about toast",
     "Did you see the baseball game yesterday?",
     "The package was delivered late and the contents were broken", 
     "Trashy television shows are some of my favorites",
     "I'm seeing a Kubrick film tomorrow, I hear not so great things about it.",
     "I find chirping birds irritating, but I know I'm not the only one",
]})
unknown

print(vectorizer.get_feature_names())

# Put it through the vectoriser
 
# transform, not fit transform, because we already learned all our words
unknown_vectors= vectorizer.transform(unknown.content)
unknown_words_df = pd. DataFrame (unknown_vectors.toarray(), columns=vectorizer.get_feature_names()) 
unknown_words_df.head()

unknown_words_df.shape

unknown['pred_logreg'] = logreg.predict(unknown_words_df)
unknown['pred_logreg_proba'] = logreg.predict_proba(unknown_words_df)[:,1]
 
unknown['pred_forest'] = forest.predict(unknown_words_df)
unknown['pred_forest_proba'] = forest.predict_proba(unknown_words_df)[:,1]
 
unknown['pred_svc'] = svc.predict(unknown_words_df)
 
unknown['pred_bayes'] = bayes.predict(unknown_words_df)
unknown['pred_bayes_proba'] = bayes.predict_proba(unknown_words_df)[:,1]

unknown